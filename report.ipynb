{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from functools import partial as par\n",
    "import functools as ft\n",
    "import time\n",
    "from ctypes import c_void_p, Structure, c_double, c_int, cdll, cast, POINTER\n",
    "from numpy.ctypeslib import ndpointer\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "def F(*z):\n",
    "    z = [*z]\n",
    "    z[0] = [z[0]]\n",
    "    return [*ft.reduce(lambda x, y: map(y, x), z)][0]\n",
    "FF = lambda *z: [*ft.reduce(lambda x, y: map(y, x), z)]\n",
    "fyx = lambda f, *x: lambda *y: f(*y, *x)\n",
    "\n",
    "lib = cdll.LoadLibrary(\"./a.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"sp500.h5\")\n",
    "temp = df[\"volume\"].groupby(level = 1)\\\n",
    "                    .apply(lambda x: x.ewm(halflife = 60).mean());\n",
    "df.loc[temp.index, \"naive\"] = temp.groupby(level = 1).shift(1);\n",
    "# print(df.loc[pd.IndexSlice[\"2000-01-01\":\"2000-01-10\", \"AAPL\"], :])\n",
    "# -> Appendix A1\n",
    "window = 5\n",
    "for i in range(window + 1):\n",
    "\tname = f\"k{i}\"\n",
    "\tdf[name] = (df[\"volume\"].groupby(level = 1).shift(i)\n",
    "                / df[\"naive\"] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvSlice = pd.IndexSlice[:\"2015-01-01\", :]\n",
    "testSlice = pd.IndexSlice[\"2015-01-01\":, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = df.loc[tvSlice].dropna(\n",
    "\tsubset = [f\"k{i}\" for i in range(window + 1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "1629303\n",
      "1466373\n"
     ]
    }
   ],
   "source": [
    "uspn = list(set(df_nona.index.get_level_values(\"uspn\").to_list()))\n",
    "uspn.sort()\n",
    "print(len(uspn))\n",
    "X, Y, w = [], [], []\n",
    "for x in uspn:\n",
    "\ttable = df_nona.loc[\n",
    "\t\tpd.IndexSlice[:, x],\n",
    "\t\t[\"sp_weight\"] + [f\"k{i}\" for i in range(window + 1)]\n",
    "\t]\n",
    "\tw.append(table[\"sp_weight\"].to_numpy())\n",
    "\tY.append(table[\"k0\"].to_numpy())\n",
    "\tX.append(np.array([\n",
    "\t\ttable[f\"k{i + 1}\"].to_numpy() for i in range(window)\n",
    "\t]).T)\n",
    "X = np.concatenate(X)\n",
    "Y = np.concatenate(Y)\n",
    "w = np.concatenate(w)\n",
    "tot = w.shape[0]\n",
    "print(tot)\n",
    "step = tot - tot // 10\n",
    "print(step)\n",
    "perm = F(tot, range, np.random.permutation)\n",
    "w = w[perm]\n",
    "X = X[perm]\n",
    "Y = Y[perm]\n",
    "X1, Y1, w1 = X[:step], Y[:step], w[:step]\n",
    "X2, Y2, w2 = X[step:], Y[step:], w[step:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_wls_iter(\n",
    "    y_next, x_next, w_next, n2, m,\n",
    "    x = np.array([]), xTwx = None, xTwy = None,\n",
    "    n1 = 0, update = False\n",
    "):\n",
    "    tot_len = n1 + 2 * n2 + m * (m + 2)\n",
    "    if xTwx is None:\n",
    "        xTwx = np.zeros((m, m))\n",
    "    if xTwy is None:\n",
    "        xTwy = np.zeros((m, 1))\n",
    "    double = lambda x: x.astype('d')\n",
    "    x_next = double(x_next)\n",
    "    w_next = double(w_next)\n",
    "    y_next = double(y_next)\n",
    "    x = double(x)\n",
    "    xTwx = double(xTwx)\n",
    "    xTwy = double(xTwy)\n",
    "    lib.wls_iter.restype = ndpointer(dtype = c_double, shape = (tot_len,))\n",
    "    results = lib.wls_iter(\n",
    "        c_void_p(x.ctypes.data),\n",
    "        c_void_p(xTwx.ctypes.data),\n",
    "        c_void_p(xTwy.ctypes.data),\n",
    "        c_void_p(x_next.ctypes.data),\n",
    "        c_void_p(w_next.ctypes.data),\n",
    "        c_void_p(y_next.ctypes.data),\n",
    "        n1, n2, m, update\n",
    "    )\n",
    "    xTwx = results[:m * m].reshape(m, m)\n",
    "    xTwy = results[m * m : m * (m + 1)]\n",
    "    predict = results[m * (m + 1) : m * (m + 2)]\n",
    "    yhat_next = results[m * (m + 2) : m * (m + 2) + n2]\n",
    "    if update:\n",
    "        yhat = results[-n1 - n2:]\n",
    "    else:\n",
    "        yhat = None\n",
    "    return xTwx, xTwy, predict, yhat_next, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 WLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.161\n",
      "Model:                            WLS   Adj. R-squared (uncentered):              0.161\n",
      "Method:                 Least Squares   F-statistic:                          5.619e+04\n",
      "Date:                Fri, 24 Feb 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        01:21:17   Log-Likelihood:                     -1.9748e+06\n",
      "No. Observations:             1466373   AIC:                                  3.950e+06\n",
      "Df Residuals:                 1466368   BIC:                                  3.950e+06\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.4102      0.001    397.854      0.000       0.408       0.412\n",
      "x2             0.0781      0.001     69.662      0.000       0.076       0.080\n",
      "x3             0.0497      0.001     44.314      0.000       0.047       0.052\n",
      "x4             0.0447      0.001     39.498      0.000       0.042       0.047\n",
      "x5             0.0465      0.001     43.677      0.000       0.044       0.049\n",
      "==============================================================================\n",
      "Omnibus:                  5444132.213   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   25649388919928.445\n",
      "Skew:                          80.222   Prob(JB):                         0.00\n",
      "Kurtosis:                   20491.426   Cond. No.                         2.14\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "0.4101946172194769\n",
      "0.0780730045510835\n",
      "0.049679224293680865\n",
      "0.044696356366053555\n",
      "0.046468297548549975\n",
      "Time Usage\n",
      "statsmodels WLS 1466373: 0.49706244468688965\n",
      "C code 1466373: 0.2261512279510498\n",
      "We get the same results for 2 methods above.\n",
      "                                 WLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.170\n",
      "Model:                            WLS   Adj. R-squared (uncentered):              0.170\n",
      "Method:                 Least Squares   F-statistic:                          6.652e+04\n",
      "Date:                Fri, 24 Feb 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        01:21:18   Log-Likelihood:                     -2.1795e+06\n",
      "No. Observations:             1629303   AIC:                                  4.359e+06\n",
      "Df Residuals:                 1629298   BIC:                                  4.359e+06\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.4219      0.001    440.277      0.000       0.420       0.424\n",
      "x2             0.0733      0.001     69.923      0.000       0.071       0.075\n",
      "x3             0.0487      0.001     45.968      0.000       0.047       0.051\n",
      "x4             0.0425      0.001     39.920      0.000       0.040       0.045\n",
      "x5             0.0459      0.001     45.653      0.000       0.044       0.048\n",
      "==============================================================================\n",
      "Omnibus:                  5944430.299   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   25114920810012.230\n",
      "Skew:                          76.002   Prob(JB):                         0.00\n",
      "Kurtosis:                   19236.443   Cond. No.                         2.14\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "0.4218881296575067\n",
      "0.07333454760041365\n",
      "0.04870767000917158\n",
      "0.042494107088011754\n",
      "0.04590773404303217\n",
      "statsmodels WLS 1629303: 0.53696608543396\n",
      "C code next 162930: 0.021859169006347656\n",
      "We get the same results for 2 methods above.\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "test = sm.WLS(Y1, X1, weights = w1, missing = \"drop\").fit()\n",
    "print(test.summary())\n",
    "time1 = time.time()\n",
    "results = c_wls_iter(Y1, X1, w1, step, window)\n",
    "xTwx = results[0]\n",
    "xTwy = results[1]\n",
    "[print(x) for x in results[2]]\n",
    "time2 = time.time()\n",
    "print(\"Time Usage\")\n",
    "print(f\"statsmodels WLS {step}:\", time1 - time0)\n",
    "print(f\"C code {step}:\", time2 - time1)\n",
    "print(\"We get the same results for 2 methods above.\")\n",
    "test = sm.WLS(Y, X, weights = w, missing = \"drop\").fit()\n",
    "print(test.summary())\n",
    "time3 = time.time()\n",
    "results = c_wls_iter(Y2, X2, w2, tot - step, window,\n",
    "                        xTwx = xTwx, xTwy = xTwy, n1 = step)\n",
    "[print(x) for x in results[2]]\n",
    "time4 = time.time()\n",
    "print(f\"statsmodels WLS {tot}:\", time3 - time2)\n",
    "print(f\"C code next {tot - step}:\", time4 - time3)\n",
    "print(\"We get the same results for 2 methods above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2769c8024000d2372e0e7315aa533eee97b6855646f860882228e565a3a4f8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
